<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Hadoop之数据仓库Hive | 风雨欲来兮丶</title><meta name="author" content="SeanXia"><meta name="copyright" content="SeanXia"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="Hive 及数据仓库简介 基本概念 Hive 是基于 Hadoop 的一个【数据仓库工具】，可以将结构化的数据文件映射为一张 hive 数据库表，并提供简单的 sql 查询功能，可以将 sql 语句转换为 MapReduce 任务进行运行。">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop之数据仓库Hive">
<meta property="og:url" content="http://www.seanxia.cn/%E5%A4%A7%E6%95%B0%E6%8D%AE/6cc88fdb.html">
<meta property="og:site_name" content="风雨欲来兮丶">
<meta property="og:description" content="Hive 及数据仓库简介 基本概念 Hive 是基于 Hadoop 的一个【数据仓库工具】，可以将结构化的数据文件映射为一张 hive 数据库表，并提供简单的 sql 查询功能，可以将 sql 语句转换为 MapReduce 任务进行运行。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/aguila-1437713-wallhere.com.jpg">
<meta property="article:published_time" content="2017-07-06T16:00:00.000Z">
<meta property="article:modified_time" content="2019-08-10T13:44:50.000Z">
<meta property="article:author" content="SeanXia">
<meta property="article:tag" content="Hive">
<meta property="article:tag" content="数据仓库">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/aguila-1437713-wallhere.com.jpg"><link rel="shortcut icon" href="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/LOGO%E9%80%8F%E6%98%8E.png"><link rel="canonical" href="http://www.seanxia.cn/%E5%A4%A7%E6%95%B0%E6%8D%AE/6cc88fdb.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: true
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: SeanXia","link":"链接: ","source":"来源: 风雨欲来兮丶","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: true,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hadoop之数据仓库Hive',
  isPost: true,
  isHome: false,
  isHighlightShrink: undefined,
  isToc: true,
  postUpdate: '2019-08-10 21:44:50'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="风雨欲来兮丶" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (false) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/headpic.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">45</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">77</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/aguila-1437713-wallhere.com.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="风雨欲来兮丶"><span class="site-name">风雨欲来兮丶</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Hadoop之数据仓库Hive</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2017-07-06T16:00:00.000Z" title="发表于 2017-07-07 00:00:00">2017-07-07</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2019-08-10T13:44:50.000Z" title="更新于 2019-08-10 21:44:50">2019-08-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">9.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>40分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id data-flag-title="Hadoop之数据仓库Hive"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="Hive-及数据仓库简介">Hive 及数据仓库简介</h2>
<h3 id="基本概念">基本概念</h3>
<p><strong>Hive 是基于 Hadoop 的一个【数据仓库工具】</strong>，可以将结构化的数据文件映射为一张 hive 数据库表，并提供简单的 sql 查询功能，可以将 sql 语句转换为 MapReduce 任务进行运行。</p>
<span id="more"></span>
<blockquote>
<p>【数据仓库】英文名称为 Data Warehouse，可简写为DW或 DWH。数据仓库，是为企业所有级别的决策制定过程，提供所有类型数据支持的战略集合。它是单个数据存储，出于分析性报告和决策支持目的而创建。为需要业务智能的企业，提供指导业务流程改进、监视时间、成本、质量以及控制。</p>
</blockquote>
<p>**Hive 的表其实就是HDFS的目录/文件夹，hive表中的数据 就是hdfs目录中的文件，并按表名把文件夹分开。**如果是分区表，则分区值是子文件夹，可以直接在M/R job里使用这些数据。</p>
<h3 id="Hive-的优缺点">Hive 的优缺点</h3>
<p>**优点：**使用SQL来快速实现简单的 MapReduce 统计，不必开发专门的 MapReduce 应用，学习成本低，十分适合数据仓库的统计分析。</p>
<p>**缺点：**只适合离线的数据处理，不支持实时查询。</p>
<h3 id="Hive与HBase的关系与区别">Hive与HBase的关系与区别</h3>
<p><strong>关系：</strong></p>
<ul>
<li>
<p>Hive与HBase其实没有必然的关系，但是由于HBase的查询语句很不好用，所以可以通过整合Hive，对存储在Hadoop群上的数据提供类SQL的接口进行操作，<strong>也就是利用Hive来操作HBase数据库</strong>。</p>
</li>
<li>
<p>他们的共同点是数据都存储在HDFS，也就是说他们都是<strong>建立于Hadoop之上</strong>。</p>
</li>
</ul>
<p><strong>区别：</strong></p>
<ul>
<li>如果你有数据仓库的需求并且你擅长写SQL并且不想写MapReduce jobs就可以用Hive代替。用 HiveQL进行select,join,等等操作。但是Hive只适合做离线的批处理，实时性不高。</li>
<li>HBase是一个分布式的NoSql数据库，像其他数据库一样提供随即读写功能。如果你需要实时访问一些数据，就把它存入HBase。你可以用Hadoop作为静态数据仓库，HBase作为数据存储，放那些进行一些操作会改变的数据。</li>
</ul>
<h3 id="数据处理的分类">数据处理的分类</h3>
<p><strong>1. 联机事务处理OLTP（on-line transaction processing）</strong></p>
<p>OLTP 是传统的关系型<a href="http://lib.csdn.net/base/mysql" rel="external nofollow noopener noreferrer" target="_blank">数据库</a>的主要应用，主要是基本的、日常的事务处理，例如银行交易。</p>
<p>OLTP 系统强调数据库内存效率，强调内存各种指标的命令率，强调绑定变量，强调并发操作。</p>
<p><strong>2. 联机分析处理OLAP（On-Line Analytical Processing）</strong></p>
<p>OLAP 是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。</p>
<p>OLAP 系统则强调数据分析，强调 SQL 执行市场，强调磁盘 I/O，强调分区等。</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz2znsy9sgj20hb06jdhf.jpg" alt></p>
<p>简而言之，<strong>数据仓库</strong>是用来做<strong>查询分析的数据库</strong>，<strong>基本不用来做插入，修改，删除操作。</strong></p>
<ul>
<li>
<p>Hive:数据仓库。</p>
</li>
<li>
<p>Hive：解释器，编译器，优化器等。</p>
</li>
<li>
<p>Hive 运行时，<strong>元数据存储在关系型数据库里面</strong>。</p>
</li>
<li>
<p>编译器将一个Hive SQL转换操作符，操作符是Hive的最小的处理单元</p>
<p>每个操作符代表HDFS的一个操作或者一道MapReduce作业。</p>
</li>
</ul>
<h2 id="Hive-架构原理">Hive 架构原理</h2>
<p><strong>1. 用户接口</strong></p>
<p>用户接口主要有三个：Client CLI、JDBC/ODBC 和 WEBUI。</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz2zt1ozkgj20dd0c80um.jpg" alt></p>
<ul>
<li>
<p>**Client CLI ：**Hive shell 命令行，最常用。Client 是 Hive 的客户端，用户连接至 Hive Server。在启动 Client 模式的时候，需要指出 Hive Server 所在节点，并且在该节点启动 Hive Server。</p>
</li>
<li>
<p>**JDBC/ODBC：**Hive的 Java 实现，与传统数据库 JDBC 类似。</p>
</li>
<li>
<p>**WEBUI：**通过浏览器访问 Hive。</p>
</li>
</ul>
<p><strong>2. 元数据存储</strong></p>
<p>Hive 将元数据存储在关系型数据库中，如 mysql、oracle、derby 。 Hive 中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。</p>
<p><strong>3. 驱动器（Driver）</strong></p>
<p>解释器、编译器、优化器完成 HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在 HDFS 中，并在随后有 MapReduce调用执行。</p>
<p><strong>4. 数据存储</strong></p>
<p>Hive 的数据存储在 HDFS 中。大部分的查询、计算由 MapReduce 完成（包含 * 的查询，比如 select * from tb 不会生成 MapRedcue 任务）</p>
<h2 id="Hive-搭建及三种模式">Hive 搭建及三种模式</h2>
<h3 id="Hive-的安装配置">Hive 的安装配置</h3>
<p><strong>1、安装Hive</strong></p>
<p>安装环境以及前提说明：首先，Hive 是依赖于 hadoop 系统的，因此在运行 Hive 之前需要保证已经搭建好 hadoop 集群环境。</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz306vwl5nj20do05p75a.jpg" alt></p>
<ul>
<li>并安装好一个关系型数据：如 mysql</li>
</ul>
<p><strong>2、配置环境变量</strong></p>
<p>– HADOOP_HOME=/xxx<br>
– HIVE_HOME=/xxx</p>
<p>这里选择配置局部的环境变量，编辑 ~/.bash_profile，具体操作参考我的另一篇文章  <a href="https://www.seanxia.cn/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/575d59a4.html">Linux常用操作个人整理</a></p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz30tsqqzoj20ht07hjrl.jpg" alt></p>
<p><strong>3、替换和添加相关jar包</strong></p>
<p>(1) 修改 Hadoop安装包下 /share/hadoop/yarn/lib 目录下的 jline-*.jar</p>
<p>将其替换成 HIVE_HOME/lib 下的 jline-2.12.jar</p>
<p>(2) 将 hive 连接 mysql 的jar包：mysql-connector-java-5.1.32-bin.jar</p>
<p>拷贝到hive解压目录的lib目录下</p>
<p><strong>4、修改配置文件（选择3种模式里的一种）见三种安装模式</strong></p>
<p><strong>5、启动 hive</strong></p>
<p>配置完环境变量，可以在任意客户端的节点上直接输入命令：hive</p>
<p>即可启动。</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz416h3zaej20k3051mx4.jpg" alt></p>
<h3 id="Hive-配置的三种模式">Hive 配置的三种模式</h3>
<p><strong>新建配置文件 hive-site.xml 在 Hive 安装包下的 conf 目录中。</strong></p>
<p>A、内嵌模式（元数据保存在内嵌的derby中，允许一个会话链接，尝试多个会话链接时会报错）【不推荐】</p>
<p>B、本地模式（本地安装mysql 替代derby存储元数据）【推荐】</p>
<p>C、远程模式（远程安装mysql 替代derby存储元数据）【推荐】</p>
<p><strong>1. 内嵌Derby单用户模式</strong></p>
<p>这种安装模式的元数据是内嵌在Derby数据库中的，只能允许一个会话连接，数据会存放到HDFS上。</p>
<p>这种方式是最简单的存储方式，只需要hive-site.xml 做如下配置便可（注：使用 derby 存储方式时，运行 hive 会在当前目录生成一个 derby 文件和一个 metastore_db）。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 内嵌模式 --&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">	    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span>					</span><br><span class="line">	    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:derby:;databaseName=metastore_db;create=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.derby.jdbc.EmbeddedDriver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.local<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>2. 本地用户模式</strong></p>
<p>这种安装方式和嵌入式的区别在于：不再使用内嵌的Derby作为元数据的存储介质，而是使用其他数据库比如 MySQL 来存储元数据且是一个多用户的模式，运行多个用户 client 连接到一个数据库中。这种方式一般作为公司内部同时使用 Hive。这里有一个前提，每一个用户必须要有对MySQL的访问权利，即每一个客户端使用者需要知道MySQL的用户名和密码才行。</p>
<p>这种存储方式需要在本地运行一个 mysql 服务器，并作如下配置（下面两种使用 mysql 的方式，需要将 mysql 的 jar 包拷贝到 Hive 安装包下的 lib 目录下。</p>
<p>hive-site.xml 配置如下：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 1.本地模式 --&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive_local/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.local<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://sean01/hive_remote?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>注意：hive和MySQL不用做HA，单节点就可以。通过设置其他节点可以访问得到数据库。</p>
<p><strong>3. 远程模式</strong></p>
<p>远程模式又分为两种：远程一体和远程分开</p>
<p>(1) 远程一体模式</p>
<p>这种存储方式需要在远端服务器运行一个 mysql 服务器，并且需要在 Hive 服务器启动 meta服务。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 远程一体模式 --&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://sean01:3306/hive?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.local<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>注：这里把</strong> <strong>hive</strong> <strong>的服务端和客户端都放在同一台服务器上了。</strong></p>
<p>(2) 远程分开模式</p>
<p>所谓远程分开模式就是在远程的前提下，把 Hive 的服务端和客户端分开放到两个不同的服务器节点上。</p>
<p><strong>服务端</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://sean01:3306/hive?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>客户端</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.local<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://sean02:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span> #这里填mysql数据库的服务器地址</span><br><span class="line">		<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>**注意启动：**必须先启动服务端，再启动客户端，否则会报错！</p>
<p>服务端：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">hive --service metastore</span><br></pre></td></tr></table></figure>
<p>客户端：直接敲 hive 即可启动</p>
<h2 id="HQL-操作">HQL 操作</h2>
<h3 id="DDL-语句">DDL 语句</h3>
<p>Hive 的数据定义语言 （[LanguageManual DDL](javascript:changelink(‘<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL','EN2ZH_CN" rel="external nofollow noopener noreferrer" target="_blank">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL’,'EN2ZH_CN</a>’);)）</p>
<p>具体参见：<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL" rel="external nofollow noopener noreferrer" target="_blank">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL</a></p>
<p><strong>重点是 hive 的建表语句和分区。</strong></p>
<h4 id="创建-删除-修改-使用数据库">创建/删除/修改/使用数据库</h4>
<p><strong>1、创建数据库（常用）</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> (DATABASE<span class="operator">|</span>SCHEMA) [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] database_name [COMMENT database_comment];</span><br></pre></td></tr></table></figure>
<p>如图：创建了一个名叫 sss 的数据库</p>
<p>查看：show databases；</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz41femxtaj20ck04hjra.jpg" alt></p>
<p><strong>2、删除数据库（不常用）</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DROP</span> (DATABASE<span class="operator">|</span>SCHEMA) [IF <span class="keyword">EXISTS</span>] database_name;</span><br></pre></td></tr></table></figure>
<p>删除一个名叫 www 的数据库</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz41ikgfcyj20cy041a9y.jpg" alt></p>
<p><strong>3、修改表数据库（不常用）</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> (DATABASE<span class="operator">|</span>SCHEMA) database_name <span class="keyword">SET</span> DBPROPERTIES (property_name<span class="operator">=</span>property_value, ...);</span><br><span class="line"><span class="keyword">ALTER</span> (DATABASE<span class="operator">|</span>SCHEMA) database_name <span class="keyword">SET</span> OWNER [<span class="keyword">USER</span><span class="operator">|</span>ROLE] user_or_role;</span><br></pre></td></tr></table></figure>
<p><strong>4、使用数据库</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">use database_name;</span><br><span class="line">Use <span class="keyword">default</span>;</span><br></pre></td></tr></table></figure>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz41qxn52hj20eb03x0sm.jpg" alt></p>
<h4 id="创建、删除表">创建、删除表</h4>
<p><strong>1、创建表（常用）</strong></p>
<p>(1) 数据类型（data_type）</p>
<ul>
<li>primitive_type  原始数据类型</li>
<li>array_type		数组</li>
<li>map_type		map</li>
<li>struct_type</li>
<li>union_type  – (Note: Available in Hive 0.7.0 and later)</li>
</ul>
<hr>
<p><code>原始数据类型 primitive_type</code></p>
<ul>
<li>
<p>TINYINT</p>
</li>
<li>
<p>SMALLINT</p>
</li>
<li>
<p>INT</p>
</li>
<li>
<p>BIGINT</p>
</li>
<li>
<p>BOOLEAN</p>
</li>
<li>
<p>FLOAT</p>
</li>
<li>
<p>DOUBLE</p>
</li>
<li>
<p>DOUBLE PRECISION</p>
</li>
<li>
<p><strong>STRING</strong> 基本可以搞定一切</p>
</li>
<li>
<p>BINARY</p>
</li>
<li>
<p>TIMESTAMP</p>
</li>
<li>
<p>DECIMAL</p>
</li>
<li>
<p>DECIMAL(precision, scale)</p>
</li>
<li>
<p>DATE</p>
</li>
<li>
<p>VARCHAR</p>
</li>
<li>
<p>CHAR</p>
</li>
</ul>
<p><code>数组（array_type）</code></p>
<ul>
<li><strong>ARRAY &lt; data_type &gt;</strong></li>
</ul>
<p><code>map（map_type）</code></p>
<ul>
<li><strong>MAP &lt; primitive_type, data_type &gt;</strong></li>
</ul>
<p><code>struct_type</code></p>
<ul>
<li>STRUCT &lt; col_name : data_type [COMMENT col_comment], …&gt;</li>
</ul>
<p><code>union_type</code></p>
<ul>
<li>UNIONTYPE &lt; data_type, data_type, … &gt;</li>
</ul>
<hr>
<p>(2) 完整的建表语句</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz4266g7jrj20fe068jsw.jpg" alt></p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz4273u0lvj20fe05t3zy.jpg" alt></p>
<p>(3) 建表实例：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> abc(</span><br><span class="line"> id <span class="type">int</span>,</span><br><span class="line"> name string,</span><br><span class="line"> age <span class="type">int</span>,</span><br><span class="line"> likes <span class="keyword">array</span><span class="operator">&lt;</span>string<span class="operator">&gt;</span>,</span><br><span class="line"> address map<span class="operator">&lt;</span>string,string<span class="operator">&gt;</span></span><br><span class="line"> )</span><br><span class="line"> <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line"> COLLECTION ITEMS TERMINATED <span class="keyword">by</span> <span class="string">&#x27;-&#x27;</span></span><br><span class="line"> map keys terminated <span class="keyword">by</span> <span class="string">&#x27;:&#x27;</span></span><br><span class="line"> lines terminated <span class="keyword">by</span> <span class="string">&#x27;\n&#x27;</span>; #可以不写，默认按换行符</span><br></pre></td></tr></table></figure>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz42fo8659j20es07xq30.jpg" alt></p>
<p><strong>同时在 NameNode 的 HDFS 上也可以看到创建的表路径</strong></p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz42iqsovzj20wt0cqwfc.jpg" alt></p>
<p>(4) <strong>导入数据</strong>（属于DML但是为了演示需要在此应用）：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">LOAD DATA [<span class="keyword">LOCAL</span>] INPATH <span class="string">&#x27;filepath&#x27;</span> [OVERWRITE] <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)]</span><br></pre></td></tr></table></figure>
<p>数据如下：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">1,zshang,18,game-girl-book,stu_addr:beijing-work_addr:shanghai</span><br><span class="line">2,lishi,16,shop-boy-book,stu_addr:hunan-work_addr:shanghai</span><br><span class="line">3,wang2mazi,20,fangniu-eat,stu_addr:shanghai-work_addr:tianjing</span><br><span class="line">4,wxiaokun,18,fangniu-book-game,stu_addr:wuhan-work_addr:nanjing</span><br><span class="line">5,xshufan,20,boy-girl-book,stu_addr:tokyo-work_addr:hangzhou</span><br></pre></td></tr></table></figure>
<p>首先在本地新建一个文件来装这些数据 ：vim  hivedata</p>
<p>然后加载到 abc 这张表中</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/root/hivedata&#x27;</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> abc;</span><br></pre></td></tr></table></figure>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz43d4kvfcj20lf065mxg.jpg" alt></p>
<p><code>注意：</code>如果不加 local 加载的就不是本地，是加载 HDFS 上的文件</p>
<p>在之前的版本，需要在路径中写全 hdfs 的路径（加上集群的名称），现在新的版本已经优化了，不加 local 就是在 hdfs 上找，加了就会到本地服务器上找。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">load data inpath <span class="string">&#x27;hdfs://Xss/hivedata&#x27;</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> abc;</span><br></pre></td></tr></table></figure>
<p><strong>2、删除表</strong></p>
<p>(1) 使用 Hive 删除表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> [IF <span class="keyword">EXISTS</span>] table_name [PURGE];</span><br></pre></td></tr></table></figure>
<p>比如删除刚刚创建的表 abc</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz43g7ugpsj20dt02mmx0.jpg" alt></p>
<p>(2) 使用 hdfs 删除表</p>
<p><strong>因为 Hive 的元数据信息存储在 mysql 上，而数据存储在 HDFS 上，所以如果用 hdfs 的命令来删除表，会删除表里的数据，并不能删除元数据信息。</strong></p>
<p>试验一下：我们用 hdfs 删除 abc 里的数据，然后重新把数据加载回来</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">hdfs dfs -rm -r /user/hive_local/warehouse/sss.db/abc/hivedata</span><br></pre></td></tr></table></figure>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz446wt97cj20mf02xdft.jpg" alt></p>
<p>删除之后 hive 中就无法查找到结果</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz447z3lhrj20cv026glf.jpg" alt></p>
<p>使用 hdfs 把数据 put 回来</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">hdfs dfs <span class="operator">-</span>put hivedata <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive_local<span class="operator">/</span>warehouse<span class="operator">/</span>sss.db<span class="operator">/</span>abc</span><br></pre></td></tr></table></figure>
<p>再次查看时，数据重新回来！</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz44dillzej20ks0400su.jpg" alt></p>
<p><code>注意区别：</code></p>
<blockquote>
<p>1、HDFS 删除的是表里的数据，不会删除表的元数据信息；</p>
<p>2、Hive删除普通表会把数据连带元数据信息一并删除；</p>
<p>3、Hive删除外部表只会删除元数据信息，不会删除数据。</p>
<p>因为 HDFS 删除和 Hive 删除普通表直接会删除数据，数据很重要，所以慎用！！！</p>
</blockquote>
<p>使用 hive 删除普通表就会连带表的元数据信息彻底的删除。<strong>所以为了防止使用 hive 时避免误删，我们引入外部表来控制 hive 删除表的操作。</strong></p>
<p><strong>3、外部表</strong></p>
<p>外部关键字 EXTERNAL 允许您创建一个表,并提供一个位置,以便 hive 不使用这个表的默认位置。<strong>这方便如果你已经生成的数据。当删除一个外部表，表中的数据不是从文件系统中删除</strong>。外部表指向任何 HDFS 的存储位置,而不是存储在配置属性指定的文件夹<a href="#ConfigurationProperties-hive.metastore.warehouse.dir','EN2ZH_CN'"> hive.metastore.warehouse.dir</a> 中。</p>
<p>开始创建外部表，需要在create 前加上关键字 external</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> person(</span><br><span class="line"> id <span class="type">int</span>,</span><br><span class="line"> name string,</span><br><span class="line"> age <span class="type">int</span>,</span><br><span class="line"> likes <span class="keyword">array</span><span class="operator">&lt;</span>string<span class="operator">&gt;</span>,</span><br><span class="line"> address map<span class="operator">&lt;</span>string,string<span class="operator">&gt;</span></span><br><span class="line"> )</span><br><span class="line"> <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line"> COLLECTION ITEMS TERMINATED <span class="keyword">by</span> <span class="string">&#x27;-&#x27;</span></span><br><span class="line"> map keys terminated <span class="keyword">by</span> <span class="string">&#x27;:&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>加载数据</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/root/hivedata&#x27;</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> abc;</span><br></pre></td></tr></table></figure>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz45gh7euvj20kx0axq3j.jpg" alt></p>
<p>然后使用 hive 删除表 abc</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz45i6w6y4j20er03ct8l.jpg" alt></p>
<p>查询 mysql 数据库，发现元数据信息已经没有了</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz45p36uosj20kz060t8r.jpg" alt></p>
<p>再看 HDFS 中，数据却还在</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz45q16ylwj20wv0bqdgp.jpg" alt></p>
<p>因为数据还在，于是只需要重新创建一下这个表就可以了</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz45t6mtf6j20l30cqmxs.jpg" alt></p>
<h4 id="修改、更新表，删除表数据">修改、更新表，删除表数据</h4>
<p>这些一般工作中很少用</p>
<ul>
<li>重命名表</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name RENAME <span class="keyword">TO</span> new_table_name;</span><br><span class="line">Eg: <span class="keyword">alter</span> <span class="keyword">table</span> meninem rename <span class="keyword">to</span> sean;</span><br></pre></td></tr></table></figure>
<ul>
<li>更新数据</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> table_name <span class="keyword">SET</span> <span class="keyword">column</span> <span class="operator">=</span> <span class="keyword">value</span> [, <span class="keyword">column</span> <span class="operator">=</span> <span class="keyword">value</span> ...] [<span class="keyword">WHERE</span> expression]</span><br></pre></td></tr></table></figure>
<ul>
<li>删除表数据</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> table_name [<span class="keyword">WHERE</span> expression]  # 需要配置权限</span><br></pre></td></tr></table></figure>
<h3 id="DML-语句">DML 语句</h3>
<p>Hive数据操作语言（[LanguageManual DML](javascript:changelink(‘<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML','EN2ZH_CN" rel="external nofollow noopener noreferrer" target="_blank">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML’,'EN2ZH_CN</a>’);)）</p>
<p>具体参见：<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML" rel="external nofollow noopener noreferrer" target="_blank">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML</a></p>
<p><strong>重点是数据加载和查询插入语法</strong></p>
<h4 id="四种插入-导入数据">四种插入/导入数据</h4>
<p>Hive 不能很好的支持用 insert 语句一条一条的进行插入操作，不支持 update 。数据是以 load 的方式加载到建立好的表中。数据一旦导入就不可以修改。</p>
<p><code>注意区分：在load数据时使用的是[overwrite] into，但是插入数据时是insert overwrite/into</code></p>
<p><strong>第一种</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">LOAD DATA [<span class="keyword">LOCAL</span>] INPATH <span class="string">&#x27;filepath&#x27;</span> [OVERWRITE] </span><br><span class="line"><span class="keyword">INTO</span> <span class="keyword">TABLE</span> table_name</span><br></pre></td></tr></table></figure>
<p><strong>第二种</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> person</span><br><span class="line">   <span class="keyword">SELECT</span> id,name,age,likes,address <span class="keyword">From</span> abc;</span><br></pre></td></tr></table></figure>
<p>先创建一个 person 表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> person(</span><br><span class="line"> id <span class="type">int</span>,</span><br><span class="line"> name string,</span><br><span class="line"> age <span class="type">int</span>,</span><br><span class="line"> likes <span class="keyword">array</span><span class="operator">&lt;</span>string<span class="operator">&gt;</span>,</span><br><span class="line"> address map<span class="operator">&lt;</span>string,string<span class="operator">&gt;</span></span><br><span class="line"> )</span><br><span class="line"> <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line"> COLLECTION ITEMS TERMINATED <span class="keyword">by</span> <span class="string">&#x27;-&#x27;</span></span><br><span class="line"> map keys terminated <span class="keyword">by</span> <span class="string">&#x27;:&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz46f20htij20ee07sq30.jpg" alt></p>
<p>再把 abc 表里的数据插入到 person 表中</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz46va6ez1j20mf0dg0tz.jpg" alt></p>
<p><strong>第三种</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> person t1</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> person2 </span><br><span class="line">       <span class="keyword">SELECT</span> t1.id, t1.name, t1.age ;</span><br></pre></td></tr></table></figure>
<p>先创建 person2 这个表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> person2(</span><br><span class="line"> id <span class="type">int</span>,</span><br><span class="line"> name string,</span><br><span class="line"> age <span class="type">int</span></span><br><span class="line"> )</span><br><span class="line"> <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz471xqs2aj20fk06c3yj.jpg" alt></p>
<p>再插入 person 表中所需的三个字段的数据，得到数据。</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz47b86sn6j20hi042748.jpg" alt></p>
<p>【from放前面好处就是后面可以插入多条语句 】</p>
<p><strong>第四种</strong></p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz464cyjmjj20h801ut8x.jpg" alt></p>
<p><code>拓展：本地load数据和从HDFS上load数据的过程有什么区别？</code></p>
<p>本地： load 会自动复制到 HDFS 上的 hive 的 ** 目录下</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1g0wll7aa1kj20fe060wew.jpg" alt></p>
<p>HDFS：load 会移动数据到 HDFS 上的 hive 的 ** 目录下，原来的就没有了。</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1g0wlndnh1fj20fe09xmyk.jpg" alt></p>
<h4 id="查询数据并保存">查询数据并保存</h4>
<p>举例：我们用 person2 这张表作为查询对象</p>
<p>先查看一下 person2 表的数据信息</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz4yntu513j20ec043dfr.jpg" alt></p>
<p><strong>A、保存数据到本地</strong></p>
<p>将 person2 表的查询信息保存到本地目录的 /root/hive_exp 下</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/root/hive_exp&#x27;</span></span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span>	#以<span class="string">&#x27;,&#x27;</span>隔开</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> person2;</span><br></pre></td></tr></table></figure>
<p>然后查看本地</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz4ykmnvdsj20fq06ajrm.jpg" alt></p>
<p><strong>B、保存到 HDFS 上</strong></p>
<p>将 person2 表的查询信息保存到 HDFS 目录的 /user/hive/hive_exp下</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite directory <span class="string">&#x27;/user/hive/hive_exp&#x27;</span></span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span>	 #以<span class="string">&#x27;,&#x27;</span>隔开</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> person2;</span><br></pre></td></tr></table></figure>
<p>然后查看 HDFS</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz4yu5jax9j20v30bj3za.jpg" alt></p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz4z14ovw5j20fa03nglj.jpg" alt></p>
<p><strong>C、在外部 shell 中将数据重定向到文件中</strong></p>
<p>有时我们在外部想利用 sql 查询表数据信息，但是又不想进到 hive 里面去，就可以用到外部 shell 的操作</p>
<p>比如：把 abc 这张表的数据标准输出重定向到本地 root 目录下的 abc.txt 文件中</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hive -e &quot;select * from sss.abc;&quot; &gt; /root/abc.txt	#注意表明前一定要带上数据库的名称，否则会找不到而报错！</span><br></pre></td></tr></table></figure>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz4zcvg56hj20ld06v0t6.jpg" alt></p>
<h4 id="备份数据或还原数据">备份数据或还原数据</h4>
<p><strong>1、备份数据</strong></p>
<p>备份使用关键字<code>export</code></p>
<p>举例：将person2表中的数据备份到 HDFS 中的目录 /user/hadoop/hive/datas 下</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">EXPORT <span class="keyword">TABLE</span> person2 <span class="keyword">TO</span> <span class="string">&#x27;/user/hadoop/hive/datas&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz4zmucmwzj20lw04pq36.jpg" alt></p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz4zoj49dkj20w60c5t9l.jpg" alt></p>
<p><strong>2、删除再还原数据</strong></p>
<p>先删除表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> person2;</span><br></pre></td></tr></table></figure>
<p>再还原数据</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">IMPORT <span class="keyword">FROM</span> <span class="string">&#x27;/user/hadoop/hive/datas&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz500jj6d8j20i40a0weu.jpg" alt></p>
<h3 id="Hive-SerDe">Hive SerDe</h3>
<p><strong>Hive SerDe</strong>（Serializer and Deserializer），SerDe 用于做序列化和反序列化。</p>
<p>构建在数据存储和执行引擎之间，对两者实现解耦。</p>
<p>Hive 通过 ROW FORMAT DELIMITED 以及 SERDE 进行内容的读写。</p>
<p><strong>1、格式：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">row_format</span><br><span class="line">: DELIMITED </span><br><span class="line">          [FIELDS TERMINATED <span class="keyword">BY</span> <span class="type">char</span> [ESCAPED <span class="keyword">BY</span> <span class="type">char</span>]] </span><br><span class="line">          [COLLECTION ITEMS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>] </span><br><span class="line">          [MAP KEYS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>] </span><br><span class="line">          [LINES TERMINATED <span class="keyword">BY</span> <span class="type">char</span>] </span><br><span class="line">: SERDE serde_name [<span class="keyword">WITH</span> SERDEPROPERTIES (property_name<span class="operator">=</span>property_value, property_name<span class="operator">=</span>property_value, ...)]</span><br></pre></td></tr></table></figure>
<p><strong>2、举例：处理一些请求数据，对数据做固定格式的清洗</strong></p>
<p>表数据文件：localhost_access_log.2016-02-29.txt</p>
<figure class="highlight excel"><table><tr><td class="code"><pre><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:35</span> +<span class="number">0800</span>] <span class="string">&quot;GET /bg-upper.png HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:35</span> +<span class="number">0800</span>] <span class="string">&quot;GET /bg-nav.png HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:35</span> +<span class="number">0800</span>] <span class="string">&quot;GET /asf-logo.png HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:35</span> +<span class="number">0800</span>] <span class="string">&quot;GET /bg-button.png HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:35</span> +<span class="number">0800</span>] <span class="string">&quot;GET /bg-middle.png HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET / HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">11217</span></span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET / HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">11217</span></span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET /tomcat.css HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET /tomcat.png HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET /asf-logo.png HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET /bg-middle.png HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET /bg-button.png HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET /bg-nav.png HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET /bg-upper.png HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET / HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">11217</span></span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET /tomcat.css HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET /tomcat.png HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET / HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">11217</span></span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET /tomcat.css HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET /tomcat.png HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET /bg-button.png HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br><span class="line"><span class="number">192.168</span>.<span class="number">57.4</span> - - [<span class="number">29</span>/Feb/<span class="symbol">2016:18</span><span class="symbol">:14</span><span class="symbol">:36</span> +<span class="number">0800</span>] <span class="string">&quot;GET /bg-upper.png HTTP/1.1&quot;</span> <span class="number">304</span> -</span><br></pre></td></tr></table></figure>
<p><strong>创建表</strong></p>
<p>Hive 正则匹配（去掉中括号和 “ ” 号）</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> logtbl (</span><br><span class="line">    host STRING,</span><br><span class="line">    <span class="keyword">identity</span> STRING, <span class="operator">/</span><span class="operator">/</span>身份</span><br><span class="line">    t_user STRING,</span><br><span class="line">    <span class="type">time</span> STRING,</span><br><span class="line">    request STRING,</span><br><span class="line">    referer STRING, <span class="operator">/</span><span class="operator">/</span>来路 </span><br><span class="line">    agent STRING)	<span class="operator">/</span><span class="operator">/</span>代理</span><br><span class="line">  <span class="type">ROW</span> FORMAT SERDE <span class="string">&#x27;org.apache.hadoop.hive.serde2.RegexSerDe&#x27;</span> <span class="operator">/</span><span class="operator">/</span>继承类</span><br><span class="line">  <span class="keyword">WITH</span> SERDEPROPERTIES (</span><br><span class="line">    &quot;input.regex&quot; <span class="operator">=</span> &quot;([^ ]*) ([^ ]*) ([^ ]*) \\[(.*)\\] \&quot;(.<span class="operator">*</span>)\&quot; (-|[0-9]*) (-|[0-9]*)&quot;</span><br><span class="line">  )		<span class="operator">/</span><span class="operator">/</span>正则</span><br><span class="line">  STORED <span class="keyword">AS</span> TEXTFILE; <span class="operator">/</span><span class="operator">/</span>存储为text文件</span><br></pre></td></tr></table></figure>
<p><strong>把数据文件上传数据到服务器，然后加载到表中</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/root/localhost_access_log.2016-02-29.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> logtbl;</span><br></pre></td></tr></table></figure>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz50pz69gij20lq0d975q.jpg" alt></p>
<h2 id="Beeline-和-Hiveser2">Beeline 和 Hiveser2</h2>
<p>Hiveserver2 是 Hive server的第二个版本。</p>
<p><strong>1、Hiveserver2 启动。</strong></p>
<p>在服务端直接使用命令 hiveserver2 即可</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz511pd9wyj20id01jjr8.jpg" alt></p>
<p>Beeline 是 在 Hive 里的，他在 Hive 安装包下的 bin 目录下</p>
<p><strong>2、启动 Beeline。</strong></p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz50xt4xinj20gm059q35.jpg" alt></p>
<p>所以只要有 Hive 就能启动 Beeline，无论是分开模式还是一体模式。</p>
<p><strong>3、Beeline 连接 hiveserver2</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">!</span><span class="keyword">connect</span> jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>sean01:<span class="number">10000</span> root <span class="number">123456</span>  #连接mysql数据库</span><br></pre></td></tr></table></figure>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz516fl90ej20hl04et8s.jpg" alt></p>
<p><strong>4、使用 Beeline 查询</strong></p>
<p>查看效果：会发现 Beeline 在格式上进行了美化，也算是优化</p>
<p><img src="/%E5%A4%A7%E6%95%B0%E6%8D%AE/6cc88fdb/C:%5CUsers%5CXss%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1547367862685.png" alt="1547367862685"></p>
<p><code>注意：在实际工作中，Beeline并不怎么用，因为非常格式上要进行切分，非常消耗资源。</code></p>
<h2 id="Hive-的-JDBC">Hive 的 JDBC</h2>
<p>一般是平台使用展示或接口，服务端启动hiveserver2后，在java代码中通过调用hive的jdbc访问默认端口10000进行连接、访问。（这种格式使用的比较少）</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz51e4lot6j20fe09vgn8.jpg" alt></p>
<h2 id="Hive-分区与自定义函数">Hive 分区与自定义函数</h2>
<h3 id="Hive-的分区（partiton）">Hive 的分区（partiton）</h3>
<blockquote>
<p>假如现在我们公司一天产生3亿的数据量，那么为了方便管理和查询，此时可以建立分区（可按日期 部门等具体业务分区）。分门别类的管理。</p>
</blockquote>
<p><strong>注意：必须在表定义时创建 partition !</strong></p>
<p>分区分为：单分区和多分区</p>
<p>分区分为：静态分区和动态分区</p>
<h4 id="创建分区">创建分区</h4>
<p><strong>A、单分区建表语句</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> day_table(id <span class="type">int</span>, content string) </span><br><span class="line">   partitioned <span class="keyword">by</span> (dt string) </span><br><span class="line">   <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>【单分区表，按天分区，在表结构中存在id，content，dt三列；以dt为文件夹区分】</p>
<p>新建数据文件 hivedata2 在本地 root 下</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz51ui9oyaj20ft03rdfs.jpg" alt></p>
<p>加载数据到分区表中</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/root/hivedata2&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> day_table <span class="keyword">partition</span>(dt<span class="operator">=</span><span class="string">&#x27;2008-08-08&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>查看表信息</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz51zxqzlcj20g804baa1.jpg" alt></p>
<p>查看表结构（使用关键字 desc）</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz522ytvoaj20hf056t8o.jpg" alt></p>
<p>查看 HDFS</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz52joijjxj20u105v74f.jpg" alt></p>
<p><code>注意：在 HDFS 中不能用‘/’和‘-’连接字段，否则会乱码。</code></p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz5280ii6lj20es04i750.jpg" alt></p>
<p><strong>B、双分区建表语句</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> day_hour_table (id <span class="type">int</span>, content string) </span><br><span class="line">  partitioned <span class="keyword">by</span> (dt string, <span class="keyword">hour</span> string) </span><br><span class="line">  <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>【双分区表，按天和小时分区，在表结构中新增加了dt和hour两列；先以dt为文件夹，再以hour子文件夹区分】</p>
<p>加载数据到双分区表中</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/root/hivedata2&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> day_hour_table <span class="keyword">partition</span>(dt<span class="operator">=</span><span class="string">&#x27;2008-08-08&#x27;</span>,<span class="keyword">hour</span><span class="operator">=</span><span class="string">&#x27;01-02&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>查看表信息</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz52h9l6n8j20fx047749.jpg" alt></p>
<p>查看 HDFS</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz52lho1rhj20u808vt8x.jpg" alt></p>
<p><strong>注意：在创建 删除多分区等操作时一定要注意分区的先后顺序，他们是父子节点的关系。分区字段不要和表字段相同</strong></p>
<h4 id="添加分区表的分区字段">添加分区表的分区字段</h4>
<p>表分区已创建，在此基础上添加具体分区。</p>
<blockquote>
<p>比如在建表的时候就已经定义了分区：partitioned by（dt string），我们可以根据这个类型新建多个分区字段，比如按天去分区，每天就是一个文件夹。</p>
</blockquote>
<p><strong>语法格式</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name</span><br><span class="line"><span class="keyword">ADD</span> partition_spec [ LOCATION <span class="string">&#x27;location1&#x27;</span> ] partition_spec [ LOCATION <span class="string">&#x27;location2&#x27;</span> ] ...</span><br></pre></td></tr></table></figure>
<p><strong>例</strong>：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> day_table <span class="keyword">add</span> <span class="keyword">partition</span>(dt<span class="operator">=</span><span class="string">&#x27;2008-08-08&#x27;</span>);</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> day_table <span class="keyword">add</span> <span class="keyword">partition</span>(dt<span class="operator">=</span><span class="string">&#x27;2008-08-09&#x27;</span>);</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> day_table <span class="keyword">add</span> <span class="keyword">partition</span>(dt<span class="operator">=</span><span class="string">&#x27;2008-08-10&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p><code>添加的前提是表在创建时已经定义了相应的分区。比如：添加一个单分区字段，前提是在创建这张表时已经定义了这个单分区，多分区同理。</code></p>
<h4 id="删除分区">删除分区</h4>
<p><strong>语法格式</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">DROP</span> partition_spec, partition_spec,...</span><br></pre></td></tr></table></figure>
<p>用户可以用 ALTER TABLE DROP PARTITION 来删除分区。分区的元数据和数据将被一并删除。</p>
<p><strong>例</strong>：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> day_hour_table <span class="keyword">drop</span> <span class="keyword">partition</span>(dt<span class="operator">=</span><span class="string">&#x27;2008-08-08&#x27;</span>);</span><br></pre></td></tr></table></figure>
<h4 id="数据加载进分区表中">数据加载进分区表中</h4>
<p><strong>语法格式</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">LOAD DATA [<span class="keyword">LOCAL</span>] INPATH <span class="string">&#x27;filepath&#x27;</span> [OVERWRITE] <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1,partcol2<span class="operator">=</span>val2 ...)]</span><br></pre></td></tr></table></figure>
<p><strong>例如</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/root/hivedata2&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> day_table <span class="keyword">partition</span>(dt<span class="operator">=</span><span class="string">&#x27;2008-08-08&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>当数据被加载至表中时，不会对数据进行任何转换，<code>Load操作只是将数据复制至Hive表对应的位置</code>。</p>
<p>数据加载时在表下自动创建一个目录基于分区的查询的语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> day_table <span class="keyword">where</span> day_table.dt <span class="operator">&gt;=</span> <span class="string">&#x27;2008-08-08&#x27;</span></span><br></pre></td></tr></table></figure>
<h4 id="查看分区语句">查看分区语句</h4>
<p>例如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> partitions day_hour_table;</span><br></pre></td></tr></table></figure>
<h4 id="重命名分区">重命名分区</h4>
<p><strong>语法格式</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">PARTITION</span> partition_spec RENAME <span class="keyword">TO</span> <span class="keyword">PARTITION</span> partition_spec;</span><br></pre></td></tr></table></figure>
<p><strong>例如</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> day_table <span class="keyword">partition</span> (tian<span class="operator">=</span><span class="string">&#x27;2018-05-01&#x27;</span>) rename <span class="keyword">to</span> <span class="keyword">partition</span> (tain<span class="operator">=</span><span class="string">&#x27;2018-06-01&#x27;</span>);</span><br></pre></td></tr></table></figure>
<h4 id="动态分区">动态分区</h4>
<p><strong>1、创建数据</strong></p>
<p>在本地文件 /root/hivedata3 中写入以下4行数据</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">aaa,US,CA</span><br><span class="line">aaa,US,CB</span><br><span class="line">bbb,CA,BB</span><br><span class="line">bbb,CA,BC</span><br></pre></td></tr></table></figure>
<p><strong>2、建立非分区表并加载数据</strong></p>
<p>创建表 t1</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t1 (name STRING, cty STRING, st STRING) </span><br><span class="line">   <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span>; </span><br></pre></td></tr></table></figure>
<p>加载数据 hivedata3</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH <span class="string">&#x27;/root/hivedata3&#x27;</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> t1;</span><br></pre></td></tr></table></figure>
<p>查询 t1</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz546be0z3j20gh0673yj.jpg" alt></p>
<p><strong>3、创建外部分区表（普通分区表也可以）</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> t2 (name STRING) PARTITIONED <span class="keyword">BY</span> (country STRING, state STRING);</span><br></pre></td></tr></table></figure>
<p>这时就需要使用动态分区来实现。</p>
<p>使用动态分区需要注意设定以下<strong>参数：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">- hive.exec.dynamic.partition</span><br><span class="line">默认值：true</span><br><span class="line">是否开启动态分区功能，默认true开启。</span><br><span class="line">使用动态分区时候，该参数必须设置成true;</span><br><span class="line"></span><br><span class="line">- hive.exec.dynamic.partition.mode</span><br><span class="line">默认值：strict</span><br><span class="line">动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区。</span><br><span class="line">一般需要设置为nonstrict</span><br><span class="line"></span><br><span class="line">- hive.exec.max.dynamic.partitions.pernode</span><br><span class="line">默认值：100</span><br><span class="line">在每个执行MR的节点上，最大可以创建多少个动态分区。</span><br><span class="line">该参数需要根据实际的数据来设定。</span><br><span class="line">比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。</span><br><span class="line"></span><br><span class="line">- hive.exec.max.dynamic.partitions</span><br><span class="line">默认值：1000</span><br><span class="line">在所有执行MR的节点上，最大一共可以创建多少个动态分区。</span><br><span class="line">同上参数解释。</span><br><span class="line"></span><br><span class="line">- hive.exec.max.created.files</span><br><span class="line">默认值：100000</span><br><span class="line">整个MR Job中，最大可以创建多少个HDFS文件。</span><br><span class="line">一般默认值足够了，除非你的数据量非常大，需要创建的文件数大于100000，可根据实际情况加以调整。</span><br><span class="line"></span><br><span class="line">- hive.error.on.empty.partition</span><br><span class="line">默认值：false</span><br><span class="line">当有空分区生成时，是否抛出异常。</span><br><span class="line">一般不需要设置。</span><br></pre></td></tr></table></figure>
<p>比如设定 当前动态分区的模式为非严格模式 nonstrict</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz53r95nijj20dd0253yb.jpg" alt></p>
<p><strong>4、插入数据</strong></p>
<p>将 t1 表的数据动态插入到 t2 表中</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> t2 <span class="keyword">PARTITION</span> (country, state) <span class="keyword">SELECT</span> name, cty, st <span class="keyword">FROM</span> t1;</span><br></pre></td></tr></table></figure>
<p>查询 t2</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz5478i4fij20f008074c.jpg" alt></p>
<h3 id="自定义函数">自定义函数</h3>
<p>常用函数无法满足日常需求，比如脱敏：去掉敏感数据</p>
<p><strong>自定义函数包括三种：UDF、UDAF、UDTF</strong></p>
<ul>
<li>
<p>UDF：一进一出</p>
</li>
<li>
<p>UDAF：聚集函数，多进一出。如：Count/max/min</p>
</li>
<li>
<p>UDTF：一进多出，如 lateralview 侧视图     explore()</p>
</li>
</ul>
<p><strong>使用方式</strong> ：在HIVE 会话中 add 自定义函数的 jar 文件，然后创建 function 继而使用函数。</p>
<h4 id="UDF-开发（常用）">UDF 开发（常用）</h4>
<p><strong>1、UDF 函数可以直接应用于 select 语句，对查询结构做格式化处理后，再输出内容。</strong></p>
<p><strong>2、编写 UDF 函数的时候需要注意一下几点：</strong></p>
<p>​	a）自定义 UDF 需要继承类 org.apache.hadoop.hive.ql.UDF。</p>
<p>​	b）需要实现 evaluate 函数，evaluate 函数支持重载。</p>
<p>​	源码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.hive.udf;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.UDF;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TuoMin</span> <span class="keyword">extends</span> <span class="title class_">UDF</span>&#123;</span><br><span class="line">	<span class="keyword">private</span> <span class="type">Text</span> <span class="variable">res</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">	<span class="keyword">public</span> Text <span class="title function_">evaluate</span><span class="params">(String str)</span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (str == <span class="literal">null</span>) &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">		&#125;</span><br><span class="line"><span class="comment">//		1***0</span></span><br><span class="line">		<span class="type">String</span> <span class="variable">first</span> <span class="operator">=</span> str.substring(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">		<span class="type">String</span> <span class="variable">last</span> <span class="operator">=</span> str.substring(str.length()-<span class="number">1</span>, str.length());</span><br><span class="line">		res.set(first + <span class="string">&quot;***&quot;</span> + last);</span><br><span class="line">		<span class="keyword">return</span> res;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>3、步骤</strong></p>
<p>​	a）把程序打包放到目标机器上去；</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz55hp4djgj20id08t3z6.jpg" alt></p>
<pre><code>b）进入 hive 客户端，添加 jar 包：
</code></pre>
<p>​	因为 jar 包添加到环境变量中，所以不用的时候要删除</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">hive <span class="operator">&gt;</span> <span class="keyword">add</span> jar <span class="operator">/</span>root<span class="operator">/</span>TuoMin.jar;</span><br><span class="line">(清除缓存时记得删除jar包 <span class="keyword">delete</span> jar <span class="operator">/</span>root<span class="operator">/</span>TuoMin.jar;)</span><br></pre></td></tr></table></figure>
<p>​	c）创建临时函数：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">hive <span class="operator">&gt;</span> <span class="keyword">create</span> temporary <span class="keyword">function</span> tuomin <span class="keyword">as</span> <span class="string">&#x27;com.hive.udf.TuoMin&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>​	d）查询 HQL 语句：</p>
<p>​	使用自定义函数 tuomin 来查询表 abc 的 name 字段</p>
<p>​	表 abc 原数据</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz5658a38pj20lf043aa6.jpg" alt></p>
<p>​	进行脱敏</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> tuomin(name) <span class="keyword">from</span> abc;</span><br></pre></td></tr></table></figure>
<p>​	<img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz563cxwquj20d104bt8l.jpg" alt></p>
<p>​	e）销毁临时函数：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">hive <span class="operator">&gt;</span> <span class="keyword">drop</span> temporary <span class="keyword">function</span> tuomin;</span><br></pre></td></tr></table></figure>
<h4 id="UDAF-自定义集函数（不用）">UDAF 自定义集函数（不用）</h4>
<p>多行进一行出，如 sum()、min()，用在 group  by 时</p>
<p>1、必须继承org.apache.hadoop.hive.ql.exec.UDAF(函数类继承)</p>
<p>​	org.apache.hadoop.hive.ql.exec.UDAFEvaluator(内部类 Eval uator 实现 UDAFEvaluator 接口)</p>
<p>2、Evaluator 需要实现 init、iterate、terminatePartial、merge、t erminate 这几个函数</p>
<ul>
<li>init()：类似于构造函数，用于 UDAF 的初始化</li>
<li>iterate()：接收传入的参数，并进行内部的轮转，返回 boolean</li>
<li>terminatePartial()：无参数，其为 iterate 函数轮转结束后，返回轮转数据，类似于 hadoop 的 				Combinermerge()，用于接收 terminatePartial 的返回结果，进行数据 merge 操作，其返回类型为 boolean</li>
<li>terminate()：返回最终的聚集函数结果</li>
</ul>
<h4 id="UDTF-（不常用）">UDTF （不常用）</h4>
<p>一进多出，如 lateral  view  explode()</p>
<h2 id="案例实战">案例实战</h2>
<h3 id="基站掉话率">基站掉话率</h3>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz56l2s4nmj20fe07t755.jpg" alt></p>
<p><strong>1、创建原始表</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> cell_monitor(</span><br><span class="line">record_time string,</span><br><span class="line">imei string,</span><br><span class="line">cell string,</span><br><span class="line">ph_num <span class="type">int</span>,</span><br><span class="line">call_num <span class="type">int</span>,</span><br><span class="line">drop_num <span class="type">int</span>,</span><br><span class="line">duration <span class="type">int</span>,</span><br><span class="line">drop_rate <span class="keyword">DOUBLE</span>,</span><br><span class="line">net_type string,</span><br><span class="line">erl string</span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">STORED <span class="keyword">AS</span> TEXTFILE;</span><br></pre></td></tr></table></figure>
<p><strong>2、结果表</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> cell_drop_monitor(</span><br><span class="line">imei string,</span><br><span class="line">total_call_num <span class="type">int</span>,</span><br><span class="line">total_drop_num <span class="type">int</span>,</span><br><span class="line">d_rate <span class="keyword">DOUBLE</span></span><br><span class="line">) </span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">STORED <span class="keyword">AS</span> TEXTFILE;</span><br></pre></td></tr></table></figure>
<p><strong>3、加载原始数据</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">LOAD DATA <span class="keyword">LOCAL</span> INPATH <span class="string">&#x27;/root/cdr_summ_imei_cell_info.csv&#x27;</span> OVERWRITE <span class="keyword">INTO</span> <span class="keyword">TABLE</span> cell_monitor;</span><br></pre></td></tr></table></figure>
<p><strong>4、找出掉线率最高的基站</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> cell_monitor cm </span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> cell_drop_monitor  </span><br><span class="line"><span class="keyword">select</span> cm.imei ,<span class="built_in">sum</span>(cm.drop_num),<span class="built_in">sum</span>(cm.duration),<span class="built_in">sum</span>(cm.drop_num)<span class="operator">/</span><span class="built_in">sum</span>(cm.duration) d_rate </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> cm.imei </span><br><span class="line">sort <span class="keyword">by</span> d_rate <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure>
<p><strong>5、查询结果表</strong></p>
<p>比如查询前十条数据</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> cell_drop_monitor limit <span class="number">10</span>;</span><br></pre></td></tr></table></figure>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz57xiqbwbj20ew066t8s.jpg" alt></p>
<h3 id="WC-单词统计">WC 单词统计</h3>
<p>案例：做一个单词统计</p>
<p>例如：新建一个叫 wc 的文件</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz57vook9wj20mb034dfs.jpg" alt></p>
<p><strong>1、建表</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> docs(line string);  #原表</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> wc(word string, totalword <span class="type">int</span>);  #统计结果表</span><br></pre></td></tr></table></figure>
<p><strong>2、加载原始数据</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/root/wc&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> docs;</span><br></pre></td></tr></table></figure>
<p><strong>3、统计</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> (<span class="keyword">select</span> explode(split(line, <span class="string">&#x27; &#x27;</span>)) <span class="keyword">as</span> word <span class="keyword">from</span> docs) w </span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> wc </span><br><span class="line">  <span class="keyword">select</span> word, <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> totalword </span><br><span class="line">  <span class="keyword">group</span> <span class="keyword">by</span> word </span><br><span class="line">  <span class="keyword">order</span> <span class="keyword">by</span> word;</span><br></pre></td></tr></table></figure>
<p><strong>4、查询结果</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> wc;</span><br></pre></td></tr></table></figure>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz58b4wzzcj20bx0cagln.jpg" alt></p>
<h2 id="分桶">分桶</h2>
<h3 id="分桶表及应用场景">分桶表及应用场景</h3>
<p>分桶表是对<strong>列值取哈希值求余</strong>的方式，将不同数据放到不同文件中存储。</p>
<p>对于hive中每一个表、分区都可以进一步进行分桶。由<strong>列的哈希值除以桶的个数</strong>来决定每条数据划分在哪个桶中。</p>
<p><strong>适用场景：</strong></p>
<p>数据抽样（ sampling ）、map-join</p>
<h3 id="开启支持分桶">开启支持分桶</h3>
<p>set hive.enforce.bucketing=true;</p>
<p>默认：false；设置为 true 之后，mr 运行时会根据bucket的个数自动分配 reduce task 个数。（用户也可以通过mapred.reduce.tasks 自己设置 reduce 任务个数，但分桶时不推荐使用）</p>
<p><code>注意：一次作业产生的桶（文件数量）和 reduce task 个数一致。</code></p>
<h3 id="往分桶表中加载数据">往分桶表中加载数据</h3>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> bucket_table <span class="keyword">select</span> columns <span class="keyword">from</span> tbl;</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> bucket_table <span class="keyword">select</span> columns <span class="keyword">from</span> tbl;	#二者选其一</span><br></pre></td></tr></table></figure>
<h3 id="桶表-抽样查询">桶表 抽样查询</h3>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> bucket_table <span class="keyword">tablesample</span>(bucket <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">4</span> <span class="keyword">on</span> columns); #抽样函数</span><br></pre></td></tr></table></figure>
<p><strong>tablesample 语法：</strong></p>
<p>tablesample(bucket x out of y)</p>
<p>x：表示从哪个bucket开始抽取数据</p>
<p>y：必须为该表总bucket数的倍数或因子</p>
<p><strong>1、创建普通表</strong></p>
<p>例：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> mm( id <span class="type">INT</span>, name STRING, age <span class="type">INT</span>)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>测试数据：</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">1,tom,11</span><br><span class="line">2,cat,22</span><br><span class="line">3,dog,33</span><br><span class="line">4,hive,44</span><br><span class="line">5,hbase,55</span><br><span class="line">6,mr,66</span><br><span class="line">7,alice,77</span><br><span class="line">8,scala,88</span><br></pre></td></tr></table></figure>
<p>在本地 root 下创建一个 hivedata4 的文件</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz58rqp9u9j20bc051jra.jpg" alt></p>
<p><strong>2、创建分桶表</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> psnbucket( id <span class="type">int</span>, name string, age <span class="type">int</span>)</span><br><span class="line">clustered <span class="keyword">by</span> (age) <span class="keyword">into</span> <span class="number">4</span> buckets </span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p><strong>3、加载数据到普通表</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/root/hivedata4&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> mm;</span><br></pre></td></tr></table></figure>
<p><strong>4、插入数据到分桶表中</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> psnbucket <span class="keyword">select</span> id, name, age <span class="keyword">from</span> mm;</span><br></pre></td></tr></table></figure>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz591dbwnzj20c305aglj.jpg" alt></p>
<p><strong>5、抽样</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> id, name, age <span class="keyword">from</span> psnbucket <span class="keyword">tablesample</span>(bucket <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">4</span> <span class="keyword">on</span> age);</span><br><span class="line"><span class="keyword">select</span> id, name, age <span class="keyword">from</span> psnbucket <span class="keyword">tablesample</span>(bucket <span class="number">2</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">4</span> <span class="keyword">on</span> age);</span><br><span class="line"><span class="keyword">select</span> id, name, age <span class="keyword">from</span> psnbucket <span class="keyword">tablesample</span>(bucket <span class="number">3</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">4</span> <span class="keyword">on</span> age);</span><br><span class="line"><span class="keyword">select</span> id, name, age <span class="keyword">from</span> psnbucket <span class="keyword">tablesample</span>(bucket <span class="number">4</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">4</span> <span class="keyword">on</span> age);</span><br></pre></td></tr></table></figure>
<p>从第一个桶开始抽一直到第四个</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz593ynk56j20g408gt8z.jpg" alt></p>
<p><code>总结：我们互发现，在分桶抽样中，抽取数据会尽量分散去取</code></p>
<p><strong>分析图：</strong></p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz598ee8hhj20ml0biq58.jpg" alt></p>
<h2 id="Hive-Lateral-View（视图）">Hive Lateral View（视图）</h2>
<p>Lateral View 用于和 UDTF 函数（explode、split）结合来使用。</p>
<p>首先通过 UDTF 函数把一个语句拆分成多行，然后通过 Lateral View 将多行结果组合成一个支持别名的虚拟表，也就是合并为一个字段。</p>
<p>主要解决在select使用UDTF做查询过程中，查询只能包含单个UDTF，不能包含其他字段、以及多个UDTF的问题。</p>
<p><code>简单说：UDTF 先一进多出，Lateral View 拿到多条数据后多进一出。</code></p>
<p><strong>语法：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> udtf(expression) tableAlias <span class="keyword">as</span> columnAlias (<span class="string">&#x27;,&#x27;</span> columnAlias)</span><br></pre></td></tr></table></figure>
<p><strong>例：</strong></p>
<p>统计人员表中共有多少种爱好、多少个城市?</p>
<p>数据来自表 abc</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz5a2tter1j20la03jaa5.jpg" alt></p>
<p>HQL语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="keyword">distinct</span>(myCol1)), <span class="built_in">count</span>(<span class="keyword">distinct</span>(myCol2))) <span class="keyword">from</span> abc </span><br><span class="line">   <span class="keyword">lateral</span> <span class="keyword">view</span> explode(likes) myTable1 <span class="keyword">as</span> myCol1 </span><br><span class="line">   <span class="keyword">lateral</span> <span class="keyword">view</span> explode(address) myTable2 <span class="keyword">as</span> myCol2, myCol3; #切记。虽然myCol3没用到，但是这里不能删，否则会因为数据个数不匹配报错，因为数据中有两种地址：学习地址和工作地址。</span><br></pre></td></tr></table></figure>
<p>显示结果：一共7种爱好、2个学习地址。</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fz5a6nr5o2j20fr02vwee.jpg" alt></p>
<h2 id="运行方式">运行方式</h2>
<p>**1、命令行方式 Cli：**控制台模式</p>
<ul>
<li>
<p>与 hdfs 交互</p>
<p>执行 dfs 命令：例如    dfs -ls /</p>
</li>
<li>
<p>与 Linux 交互</p>
<p>！ 开头：例如    ！pwd</p>
</li>
</ul>
<p>**2、脚本运行方式：**实际生产环境中使用最多</p>
<ul>
<li>
<p>hive -e &quot; SQL 语句 &quot;</p>
</li>
<li>
<p>hive -e &quot; &quot; &gt; aaa</p>
</li>
<li>
<p>hive -S -e “” &gt; aaa   -S意思是静默模式，不打印 log 日志信息</p>
</li>
<li>
<p>hive -f file（file里可以放很多SQL语句）</p>
</li>
<li>
<p>hive -i  /home/my/hive-init.sql</p>
</li>
<li>
<p>hive &gt; source file (在 hive cli 中运行)</p>
</li>
</ul>
<p><strong>3、JDBC 方式</strong></p>
<p>hiveserver2</p>
<p><strong>4、Web GUI 接口</strong></p>
<p>hwi、hue等</p>
<p><strong>Hive Web GUI接口</strong></p>
<p>web界面安装：</p>
<p>1、下载源码包apache-hive-*-src.tar.gz</p>
<p>2、将hwi war包放在$HIVE_HOME/lib/</p>
<p>制作方法：将hwi/web/*里面所有的文件打成war包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd apache-hive-1.2.1-src/hwi/web jar -cvf hive-hwi.war *</span><br></pre></td></tr></table></figure>
<p>3、复制tools.jar(在jdk的lib目录下)到$HIVE_HOME/lib下</p>
<p>4、修改hive-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.hwi.listen.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.hwi.listen.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>9999<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.hwi.war.file<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>lib/hive-hwi.war<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>5、启动hwi服务(端口号9999)</p>
<p>hive --service hwi</p>
<p>6、浏览器通过以下链接来访问</p>
<p><a href="http://sean03:9999/hwi/" rel="external nofollow noopener noreferrer" target="_blank">http://sean03:9999/hwi/</a></p>
<h2 id="Hive参数与变量">Hive参数与变量</h2>
<p><strong>Hive当中的参数、变量</strong></p>
<p>hive当中的参数、变量，都是以命名空间开头</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1g0omwc9twlj20ez04z750.jpg" alt></p>
<p><code>通过$&#123;&#125;方式进行引用，其中system、env下的变量必须以前缀开头。</code></p>
<p><strong>Hive 参数设置方式</strong></p>
<p>1、修改配置文件 ${HIVE_HOME}/conf/hive-site.xml</p>
<p>2、启动hive cli时，通过–hiveconf key=value的方式进行设置</p>
<p>​	例：hive --hiveconf hive.cli.print.header=true</p>
<p>3、进入cli之后，通过使用set命令设置</p>
<p><strong>Hive set命令</strong></p>
<p>在 hive CLI 控制台可以通过set对hive中的参数进行查询、设置。</p>
<ul>
<li>
<p>set 设置：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set hive.cli.print.header=true;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>set 查看：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set hive.cli.print.header</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>hive参数初始化配置</p>
<p>当前用户家目录下的.hiverc文件，如:   ~/.hiverc</p>
<p>如果没有，可直接创建该文件，将需要设置的参数写到该文件中，hive启动运行时，会加载改文件中的配置。</p>
</li>
<li>
<p>hive历史操作命令集</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">~/.hivehistory</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="权限管理">权限管理</h2>
<h3 id="权限类别">权限类别</h3>
<p><strong>1、Storage Based Authorization in the Metastore Server基于存储的授权</strong></p>
<p>可以对Metastore中的元数据进行保护，但是没有提供更加细粒度的访问控制（例如：列级别、行级别）。</p>
<p><strong>2、Default Hive Authorization (Legacy Mode)  hive默认授权</strong></p>
<p>设计目的仅仅只是为了防止用户产生误操作，而不是防止恶意用户访问未经授权的数据。</p>
<p><strong>3、SQL Standards Based Authorization in HiveServer2基于SQL标准的Hive授权</strong></p>
<p>完全兼容SQL的授权模型，推荐使用该模式。</p>
<p>基于SQL标准Hive授权模型，除支持对于用户的授权认证，还支持角色role的授权认证，role可理解为是一组权限的集合，通过role为用户授权。一个用户可以具有一个或多个角色，默认包含俩种角色：public、admin</p>
<h3 id="授权限制">授权限制</h3>
<p>1、启用当前认证方式之后，dfs, add, delete, compile, and reset等命令被禁用。</p>
<p>2、通过set命令设置hive configuration的方式被限制某些用户使用。</p>
<p>（可通过修改配置文件hive-site.xml中hive.security.authorization.sqlstd.confwhitelist进行配置）</p>
<p>3、添加、删除函数以及宏（批量规模）的操作，仅为具有admin的用户开放。</p>
<p>4、用户自定义函数（开放支持永久的自定义函数），可通过具有admin角色的用户创建，其他用户都可以使用。</p>
<p>5、Transform功能被禁用</p>
<p>在 hive 服务端修改配置文件 hive-site.xml 添加以下配置内容：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.security.authorization.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>	//开启用户权限认证</span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.enable.doAs<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span>	//默认true，设为false查询将以运行hiveserver2进程的用户运行</span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.users.in.admin.role<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  //超级管理员角色用户</span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.security.authorization.manager<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.security.authenticator.manager<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hive.ql.security.SessionStateUserAuthenticator<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>服务端启动hiveserver2；客户端通过beeline进行连接</strong></p>
<p>角色的添加、删除、查看、设置：</p>
<p>CREATE ROLE role_name;  				– 创建角色</p>
<p>DROP ROLE role_name;  				– 删除角色</p>
<p>SET ROLE (role_name|ALL|NONE); 		– 设置角色</p>
<p>SHOW CURRENT ROLES;  – 查看当前具有的角色</p>
<p>SHOW ROLES;  – 查看所有存在的角色</p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fzgtw2sm5aj20nj09wwfv.jpg" alt></p>
<p><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/7308598bgy1fzgtwlm6ndj20rs0a6tac.jpg" alt></p>
<h2 id="思考总结">思考总结</h2>
<p><strong>1、Hive中的自定义函数的jar包放置</strong></p>
<p>Hive自定义的函数jar包最好放置到分布式存储系统HDFS上，这样可以有效的防止当前节点服务器发生意外宕机，jar 包丢失。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://www.seanxia.cn">SeanXia</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://www.seanxia.cn/%E5%A4%A7%E6%95%B0%E6%8D%AE/6cc88fdb.html">http://www.seanxia.cn/%E5%A4%A7%E6%95%B0%E6%8D%AE/6cc88fdb.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external nofollow noopener noreferrer">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://www.seanxia.cn" target="_blank">风雨欲来兮丶</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hive/">Hive</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/">数据仓库</a></div><div class="post_share"><div class="addtoany"><div class="a2a_kit a2a_kit_size_32 a2a_default_style"><a class="a2a_button_wechat"></a><a class="a2a_button_sina_weibo"></a><a class="a2a_button_email"></a><a class="a2a_button_copy_link"></a><a class="a2a_dd" href="https://www.addtoany.com/share" rel="external nofollow noopener noreferrer" target="_blank"></a></div></div><script async="async" src="https://static.addtoany.com/menu/page.js"></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赏一个</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/%E5%BE%AE%E4%BF%A110%E5%85%83%E8%B5%9E%E8%B5%8F%E7%A0%81.jpg" target="_blank" rel="external nofollow noopener noreferrer"><img class="post-qr-code-img" src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/%E5%BE%AE%E4%BF%A110%E5%85%83%E8%B5%9E%E8%B5%8F%E7%A0%81.jpg" alt="微信"></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/%E6%94%AF%E4%BB%98%E5%AE%9D%E6%94%B6%E6%AC%BE%E7%A0%81.jpg" target="_blank" rel="external nofollow noopener noreferrer"><img class="post-qr-code-img" src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/%E6%94%AF%E4%BB%98%E5%AE%9D%E6%94%B6%E6%AC%BE%E7%A0%81.jpg" alt="支付宝"></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/%E5%A4%A7%E6%95%B0%E6%8D%AE/9018532c.html" title="Hive中的优化策略"><img class="cover" src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/aguila-1437713-wallhere.com.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Hive中的优化策略</div></div></a></div><div class="next-post pull-right"><a href="/%E5%A4%A7%E6%95%B0%E6%8D%AE/9acfc12.html" title="深入Zookeeper"><img class="cover" src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/aguila-1437713-wallhere.com.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">深入Zookeeper</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/%E5%A4%A7%E6%95%B0%E6%8D%AE/9018532c.html" title="Hive中的优化策略"><img class="cover" src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/aguila-1437713-wallhere.com.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2017-07-15</div><div class="title">Hive中的优化策略</div></div></a></div></div></div><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/headpic.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info__name">SeanXia</div><div class="author-info__description">路虽远行则将至，事虽难作则必成！</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">45</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">77</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" href="https://github.com/Sdreamery" rel="external nofollow noopener noreferrer" target="_blank"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Sdreamery" target="_blank" title="Github" rel="external nofollow noopener noreferrer"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:sean.xs@foxmail.com" target="_blank" title="Email" rel="external nofollow noopener noreferrer"><i class="fas fa-envelope" style="color: #24292e;"></i></a><a class="social-icon" href="https://www.seanxia.cn/atom.xml" target="_blank" title="RSS"><i class="fas fa-rss" style="color: #24292e;"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E5%8F%8A%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E7%AE%80%E4%BB%8B"><span class="toc-number">1.</span> <span class="toc-text">Hive 及数据仓库简介</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">1.1.</span> <span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive-%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">1.2.</span> <span class="toc-text">Hive 的优缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive%E4%B8%8EHBase%E7%9A%84%E5%85%B3%E7%B3%BB%E4%B8%8E%E5%8C%BA%E5%88%AB"><span class="toc-number">1.3.</span> <span class="toc-text">Hive与HBase的关系与区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%9A%84%E5%88%86%E7%B1%BB"><span class="toc-number">1.4.</span> <span class="toc-text">数据处理的分类</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text">Hive 架构原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E6%90%AD%E5%BB%BA%E5%8F%8A%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F"><span class="toc-number">3.</span> <span class="toc-text">Hive 搭建及三种模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive-%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE"><span class="toc-number">3.1.</span> <span class="toc-text">Hive 的安装配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive-%E9%85%8D%E7%BD%AE%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F"><span class="toc-number">3.2.</span> <span class="toc-text">Hive 配置的三种模式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HQL-%E6%93%8D%E4%BD%9C"><span class="toc-number">4.</span> <span class="toc-text">HQL 操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#DDL-%E8%AF%AD%E5%8F%A5"><span class="toc-number">4.1.</span> <span class="toc-text">DDL 语句</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA-%E5%88%A0%E9%99%A4-%E4%BF%AE%E6%94%B9-%E4%BD%BF%E7%94%A8%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">4.1.1.</span> <span class="toc-text">创建&#x2F;删除&#x2F;修改&#x2F;使用数据库</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E3%80%81%E5%88%A0%E9%99%A4%E8%A1%A8"><span class="toc-number">4.1.2.</span> <span class="toc-text">创建、删除表</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E3%80%81%E6%9B%B4%E6%96%B0%E8%A1%A8%EF%BC%8C%E5%88%A0%E9%99%A4%E8%A1%A8%E6%95%B0%E6%8D%AE"><span class="toc-number">4.1.3.</span> <span class="toc-text">修改、更新表，删除表数据</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DML-%E8%AF%AD%E5%8F%A5"><span class="toc-number">4.2.</span> <span class="toc-text">DML 语句</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9B%E7%A7%8D%E6%8F%92%E5%85%A5-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="toc-number">4.2.1.</span> <span class="toc-text">四种插入&#x2F;导入数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2%E6%95%B0%E6%8D%AE%E5%B9%B6%E4%BF%9D%E5%AD%98"><span class="toc-number">4.2.2.</span> <span class="toc-text">查询数据并保存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%87%E4%BB%BD%E6%95%B0%E6%8D%AE%E6%88%96%E8%BF%98%E5%8E%9F%E6%95%B0%E6%8D%AE"><span class="toc-number">4.2.3.</span> <span class="toc-text">备份数据或还原数据</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive-SerDe"><span class="toc-number">4.3.</span> <span class="toc-text">Hive SerDe</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Beeline-%E5%92%8C-Hiveser2"><span class="toc-number">5.</span> <span class="toc-text">Beeline 和 Hiveser2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E7%9A%84-JDBC"><span class="toc-number">6.</span> <span class="toc-text">Hive 的 JDBC</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E5%88%86%E5%8C%BA%E4%B8%8E%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0"><span class="toc-number">7.</span> <span class="toc-text">Hive 分区与自定义函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive-%E7%9A%84%E5%88%86%E5%8C%BA%EF%BC%88partiton%EF%BC%89"><span class="toc-number">7.1.</span> <span class="toc-text">Hive 的分区（partiton）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E5%88%86%E5%8C%BA"><span class="toc-number">7.1.1.</span> <span class="toc-text">创建分区</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0%E5%88%86%E5%8C%BA%E8%A1%A8%E7%9A%84%E5%88%86%E5%8C%BA%E5%AD%97%E6%AE%B5"><span class="toc-number">7.1.2.</span> <span class="toc-text">添加分区表的分区字段</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E5%88%86%E5%8C%BA"><span class="toc-number">7.1.3.</span> <span class="toc-text">删除分区</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E8%BF%9B%E5%88%86%E5%8C%BA%E8%A1%A8%E4%B8%AD"><span class="toc-number">7.1.4.</span> <span class="toc-text">数据加载进分区表中</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E5%88%86%E5%8C%BA%E8%AF%AD%E5%8F%A5"><span class="toc-number">7.1.5.</span> <span class="toc-text">查看分区语句</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8D%E5%91%BD%E5%90%8D%E5%88%86%E5%8C%BA"><span class="toc-number">7.1.6.</span> <span class="toc-text">重命名分区</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E5%88%86%E5%8C%BA"><span class="toc-number">7.1.7.</span> <span class="toc-text">动态分区</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0"><span class="toc-number">7.2.</span> <span class="toc-text">自定义函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#UDF-%E5%BC%80%E5%8F%91%EF%BC%88%E5%B8%B8%E7%94%A8%EF%BC%89"><span class="toc-number">7.2.1.</span> <span class="toc-text">UDF 开发（常用）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#UDAF-%E8%87%AA%E5%AE%9A%E4%B9%89%E9%9B%86%E5%87%BD%E6%95%B0%EF%BC%88%E4%B8%8D%E7%94%A8%EF%BC%89"><span class="toc-number">7.2.2.</span> <span class="toc-text">UDAF 自定义集函数（不用）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#UDTF-%EF%BC%88%E4%B8%8D%E5%B8%B8%E7%94%A8%EF%BC%89"><span class="toc-number">7.2.3.</span> <span class="toc-text">UDTF （不常用）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98"><span class="toc-number">8.</span> <span class="toc-text">案例实战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E7%AB%99%E6%8E%89%E8%AF%9D%E7%8E%87"><span class="toc-number">8.1.</span> <span class="toc-text">基站掉话率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WC-%E5%8D%95%E8%AF%8D%E7%BB%9F%E8%AE%A1"><span class="toc-number">8.2.</span> <span class="toc-text">WC 单词统计</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E6%A1%B6"><span class="toc-number">9.</span> <span class="toc-text">分桶</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%A1%B6%E8%A1%A8%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">9.1.</span> <span class="toc-text">分桶表及应用场景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%80%E5%90%AF%E6%94%AF%E6%8C%81%E5%88%86%E6%A1%B6"><span class="toc-number">9.2.</span> <span class="toc-text">开启支持分桶</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BE%80%E5%88%86%E6%A1%B6%E8%A1%A8%E4%B8%AD%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE"><span class="toc-number">9.3.</span> <span class="toc-text">往分桶表中加载数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A1%B6%E8%A1%A8-%E6%8A%BD%E6%A0%B7%E6%9F%A5%E8%AF%A2"><span class="toc-number">9.4.</span> <span class="toc-text">桶表 抽样查询</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-Lateral-View%EF%BC%88%E8%A7%86%E5%9B%BE%EF%BC%89"><span class="toc-number">10.</span> <span class="toc-text">Hive Lateral View（视图）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E6%96%B9%E5%BC%8F"><span class="toc-number">11.</span> <span class="toc-text">运行方式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E5%8F%82%E6%95%B0%E4%B8%8E%E5%8F%98%E9%87%8F"><span class="toc-number">12.</span> <span class="toc-text">Hive参数与变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86"><span class="toc-number">13.</span> <span class="toc-text">权限管理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9D%83%E9%99%90%E7%B1%BB%E5%88%AB"><span class="toc-number">13.1.</span> <span class="toc-text">权限类别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%88%E6%9D%83%E9%99%90%E5%88%B6"><span class="toc-number">13.2.</span> <span class="toc-text">授权限制</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E6%80%BB%E7%BB%93"><span class="toc-number">14.</span> <span class="toc-text">思考总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98/f3ddb040.html" title="记录一次生产数据库紧急恢复经历"><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/blog/pexels-amolmande-2684011.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="记录一次生产数据库紧急恢复经历"></a><div class="content"><a class="title" href="/%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98/f3ddb040.html" title="记录一次生产数据库紧急恢复经历">记录一次生产数据库紧急恢复经历</a><time datetime="2024-07-19T16:00:00.000Z" title="发表于 2024-07-20 00:00:00">2024-07-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98/64d019ba.html" title="Linux定时备份异常处理"><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/blog/pexels-nemuel-6424584.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux定时备份异常处理"></a><div class="content"><a class="title" href="/%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98/64d019ba.html" title="Linux定时备份异常处理">Linux定时备份异常处理</a><time datetime="2024-07-16T16:00:00.000Z" title="发表于 2024-07-17 00:00:00">2024-07-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E5%85%B6%E4%BB%96/6d60df94.html" title="使用Git系统搭建GitLab"><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/aguila-1437713-wallhere.com.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="使用Git系统搭建GitLab"></a><div class="content"><a class="title" href="/%E5%85%B6%E4%BB%96/6d60df94.html" title="使用Git系统搭建GitLab">使用Git系统搭建GitLab</a><time datetime="2019-08-23T16:00:00.000Z" title="发表于 2019-08-24 00:00:00">2019-08-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E5%85%B6%E4%BB%96/7fb68dad.html" title="新浪微博图床迁移"><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/aguila-1437713-wallhere.com.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="新浪微博图床迁移"></a><div class="content"><a class="title" href="/%E5%85%B6%E4%BB%96/7fb68dad.html" title="新浪微博图床迁移">新浪微博图床迁移</a><time datetime="2019-08-10T16:00:00.000Z" title="发表于 2019-08-11 00:00:00">2019-08-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E5%A4%A7%E6%95%B0%E6%8D%AE/31afedf9.html" title="流式框架Flink（一）"><img src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/aguila-1437713-wallhere.com.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="流式框架Flink（一）"></a><div class="content"><a class="title" href="/%E5%A4%A7%E6%95%B0%E6%8D%AE/31afedf9.html" title="流式框架Flink（一）">流式框架Flink（一）</a><time datetime="2019-01-01T16:00:00.000Z" title="发表于 2019-01-02 00:00:00">2019-01-02</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/aguila-1437713-wallhere.com.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By SeanXia</div><div class="framework-info"><span>框架 </span><a href="https://hexo.io" rel="external nofollow noopener noreferrer" target="_blank">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" rel="external nofollow noopener noreferrer" target="_blank">Butterfly</a></div><div class="footer_custom_text"><a href="https://www.upyun.com/?utm_source=lianmeng&utm_medium=referral" rel="external nofollow noopener noreferrer" target="_blank"><span>本网站由</span><img class="icp-icon" src="https://seanxia.oss-cn-shanghai.aliyuncs.com/img/hexo/%E5%8F%88%E6%8B%8D%E4%BA%91_logo5.png"><span>提供 CSDN 加速/云存储服务</span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button class="share" type="button" title="分享链接" onclick="share()"><i class="fas fa-share-nodes"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button><button id="go-down" type="button" title="直达底部" onclick="btf.scrollToDest(document.body.scrollHeight, 500)"><i class="fas fa-arrow-down"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>(() => {
  const initGitalk = () => {
    const gitalk = new Gitalk(Object.assign({
      clientID: '6426e1d3285a84ce7134',
      clientSecret: '30e13e4623fd734097033c1edb8c8af6934f5c88',
      repo: 'Sdreamery.github.io',
      owner: 'Sdreamery',
      admin: ['Sdreamery'],
      id: '2496a9ad075e3b4593c2f30854fdd249',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async() => {
    if (typeof Gitalk === 'function') initGitalk()
    else {
      await getCSS('https://cdn.jsdelivr.net/npm/gitalk@1.8.0/dist/gitalk.min.css')
      await getScript('https://cdn.jsdelivr.net/npm/gitalk@1.8.0/dist/gitalk.min.js')
      initGitalk()
    }
  }
  
  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  if ('Gitalk' === 'Gitalk' || !true) {
    if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script src="https://cdn.bootcdn.net/ajax/libs/clipboard.js/2.0.11/clipboard.min.js"></script><script src="/source/js/script.js?1"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zindex="-1" mobile="true" data-click="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>